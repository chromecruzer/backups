// import * as fs from "fs-extra";
// import * as xlsx from "xlsx";
// import util from "util";
// import _ from "lodash";
// import { InputToSqlMapping } from "../../datatypes/src";
// import { NotificationsServer } from "./index";
// const dump = (obj, depth = null) => util.inspect(obj, { depth, colors: true });
// import { readFileAsBuffer } from "@bunvader/rustacean/index"

// const checkLength = (datum, mapping, cell) => {
//   const regex = /char\((\d+)\)/;
//   const sqlLength = parseInt(regex.test(mapping.sqlType) ? regex.exec(mapping.sqlType)[1] : '0');
//   switch (true) {
//     case sqlLength === 0:
//       return;
//     case !_.isString(datum):
//       console.error(`datum '${datum}' does not have a value ${dump(cell)} for mapping ${dump(mapping)}`);
//       return;
//     case sqlLength < datum.length:
//       console.error(`datum '${datum}' length ${datum.length} won't fit in sql ${dump(mapping)}`);
//       return;
//     default:
//   }
// }

// export default class LoadXlsxData {
//   fs = fs;
//   xlsx = xlsx;
//   public bulkData: (string | number | Date)[][];
//   public lotNumbers: string[];
//   headers: string[];

//   constructor(protected ns = null as (NotificationsServer | null)) {
//     this.bulkData = [];
//     this.headers = [];
//   }

//   async scanForLotNumbers(xlsxPath: string) {
//     console.log(`called with ${xlsxPath}`);
//     this.bulkData = [];
//     const newLotNumbers = [];
//     const sheet = await this.readFirstSheet(xlsxPath);
//     let emptyRowCounter = 0;
//     let row = 1;

//     while (emptyRowCounter < 8) {
//       const lotNumber = this.findLotNumber(row, sheet);
//       // console.log(`read sheet row ${row} found ${lotNumber}`);
//       if (_.isString(lotNumber)) {
//         newLotNumbers.push(lotNumber);
//         emptyRowCounter = 0;
//       } else {
//         emptyRowCounter += 1;
//       }
//       row++;
//     }
//     console.log(`scanForLotNumbers found original ${newLotNumbers.length} records versus ${_.uniq(newLotNumbers).length} unique records`)
//     this.lotNumbers = newLotNumbers;
//   }

//   private findLotNumber(row, sheet) {
//     const cellAddress = `A${row}`;
//     const cell = sheet[cellAddress];
//     if (cell) {
//       // console.log(`cell contents ${dump(cell)}`);
//       switch (cell.t) {
//         case 'n':
//           return _.toString(cell.w);
//         case 's':
//           if (!_.isEmpty(cell.w)) {
//             return cell.w;
//           }
//           break;
//         default:
//       }
//     }
//     return null;
//   }

//   async readWithMap(xlsxPath: string, mapping: InputToSqlMapping[]) {
//     const firstSheet = await this.readFirstSheet(xlsxPath);
//     let emptyRow = false;
//     this.loadHeaders(firstSheet);
//     let row = 2; //row 1 is the headers
//     // console.log(`reading with mapping ${dump(mapping)} from ${xlsxPath}`)
//     // console.log(`and received ${dump(firstSheet)}`)
//     while (!emptyRow) {
//       const dataRow: (Date | string | number)[] = [];
//       emptyRow = true;
//       mapping.forEach(c => {
//         const cellAddress = `${c.xlsxAddress}${row}`;
//         let datum: (Date | string | number) = null;
//         if (firstSheet[cellAddress] !== undefined) {
//           const cellValue = firstSheet[cellAddress].w || firstSheet[cellAddress].v;
//           emptyRow = false;
//           switch (c.dataType) {
//             case 'date':
//               datum = new Date(cellValue);
//               break;
//             case 'number':
//               datum = parseInt(cellValue);
//               break;
//             case 'string':
//               datum = cellValue;
//               checkLength(datum, c, firstSheet[cellAddress]);
//               break;
//             default:
//               datum = cellValue;
//           }
//         }
//         // console.log(`datum ${datum} row
//         // is ${emptyRow ? '' : ' not'} empty
//         // from ${dump(firstSheet[cellAddress])}`);

//         dataRow.push(datum);
//       });
//       if (!emptyRow) {
//         this.bulkData.push(dataRow);
//         row++;
//       }
//     }
//   }

//   // async readWithMap(xlsxPath: string, mapping: InputToSqlMapping[]) {
//   //   const firstSheet = await this.readFirstSheet(xlsxPath);
//   //   let row = 2; // start reading from the second row
//   //   let emptyRow = false;

//   //   // Load headers
//   //   this.loadHeaders(firstSheet);

//   //   while (!emptyRow) {
//   //     const dataRow: (Date | string | number)[] = [];
//   //     emptyRow = true;

//   //     mapping.forEach(c => {
//   //       const cellAddress = `${c.xlsxAddress}${row}`;
//   //       let datum: (Date | string | number) = null;

//   //       if (firstSheet[cellAddress] !== undefined) {
//   //         const cellValue = firstSheet[cellAddress].w || firstSheet[cellAddress].v;
//   //         emptyRow = false;

//   //         switch (c.dataType) {
//   //           case 'date':
//   //             datum = new Date(cellValue);
//   //             break;
//   //           case 'number':
//   //             datum = parseInt(cellValue);
//   //             break;
//   //           case 'string':
//   //             datum = cellValue;
//   //             checkLength(datum, c, firstSheet[cellAddress]);
//   //             break;
//   //           default:
//   //             datum = cellValue;
//   //         }
//   //       }

//   //       dataRow.push(datum);
//   //     });

//   //     if (!emptyRow) {
//   //       this.bulkData.push(dataRow);

//   //       // Optional: Process in batches
//   //       if (this.bulkData.length >= 90000) { // Adjust batch size as needed
//   //         await this.processBatch(this.bulkData);
//   //         this.bulkData = []; // Clear the bulkData after processing
//   //       }

//   //       row++;
//   //     }
//   //   }

//   //   // Final batch processing for any remaining data
//   //   if (this.bulkData.length > 0) {
//   //     await this.processBatch(this.bulkData);
//   //     this.bulkData = []; // Clear after final processing
//   //   }
//   // }

//   // New method to process batches
//   private async processBatch(dataBatch: (Date | string | number)[][]) {
//     // Implement your logic to save the batch to the database or process it
//     console.log(`Processing batch of ${dataBatch.length} records`);
//     // Example: await this.saveToDatabase(dataBatch);
//   }


//   private loadHeaders(firstSheet) {
//     let col = 0;
//     let header;
//     do {
//       header = null;
//       const cellAddress = xlsx.utils.encode_cell({ r: 0, c: col });
//       // console.log(`header cell ${dump(firstSheet[cellAddress])}`)
//       if (_.isObject(firstSheet[cellAddress])) {
//         header = firstSheet[cellAddress].w;
//         // console.log(`header for cell ${cellAddress} column ${col} is ${dump(header)}`)
//         this.headers.push(header);
//       }
//       col += 1;
//     } while (header);
//   }
//   private async readFirstSheet(xlsxPath: string) {
//     if(this.ns) {
//       this.ns.notify('INFO', `reading IOL Report`,
//         `reading from ${xlsxPath}`, ['iolUpload'])
//     }
//     console.info(`reading from ${xlsxPath}`);
//     const buffer = await this.fs.readFile(xlsxPath)
//       .catch(err => {
//         throw new Error(`"${xlsxPath}" could not be read because ${err}`)
//       });
//     const sheets = this.xlsx.read(buffer, {type: 'buffer'});
//     // console.log(`read sheets ${dump(sheets)}`);
//     return sheets.Sheets[sheets.SheetNames[0]];
//   }
//   // private async readFirstSheet(xlsxPath: string) {
//   //   if (this.ns) {
//   //     this.ns.notify('INFO', `Reading IOL Report`, `Reading from ${xlsxPath}`, ['iolUpload']);
//   //   }
//   //   console.info(`Reading from ${xlsxPath}`);

//   //   const stream = this.fs.createReadStream(xlsxPath);
//   //   const buffers = [];

//   //   return new Promise((resolve, reject) => {
//   //     stream.on("data", (chunk) => buffers.push(chunk));
//   //     stream.on("end", () => {
//   //       const buffer = Buffer.concat(buffers);
//   //       const sheets = this.xlsx.read(buffer, { type: 'buffer' });
//   //       resolve(sheets.Sheets[sheets.SheetNames[0]]);
//   //     });
//   //     stream.on("error", (error) => reject(`"${xlsxPath}" could not be read: ${error}`));
//   //   });
//   // }

//   // RS-FUSION
//   // async readFirstSheet(xlsxPath) {
//   //   if (this.ns) {
//   //     this.ns.notify('INFO', `Reading IOL Report via RS-FUSION`, `Reading from ${xlsxPath}`, ['iolUpload']);
//   //   }
//   //   console.info(`Reading from ${xlsxPath} via RS-FUSION`);

//   //   // Call the RS-FUSION function to read the file as a Buffer
//   //   const buffer = await readFileAsBuffer(xlsxPath);

//   //   // Pass the buffer directly to the xlsx library
//   //   const sheets = this.xlsx.read(buffer, { type: 'buffer' });
//   //   return sheets.Sheets[sheets.SheetNames[0]];
//   // }


// }

import * as fs from "fs-extra";
import * as xlsx from "xlsx";
import util from "util";
import _ from "lodash";
import { InputToSqlMapping } from "../../datatypes/src";
import { NotificationsServer } from "./index";

const dump = (obj, depth = null) => util.inspect(obj, { depth, colors: true });

const checkLength = (datum, mapping, cell) => {
  const regex = /char\((\d+)\)/;
  const sqlLength = parseInt(regex.test(mapping.sqlType) ? regex.exec(mapping.sqlType)[1] : '0');
  switch (true) {
    case sqlLength === 0:
      return;
    case !_.isString(datum):
      console.error(`datum '${datum}' does not have a value ${dump(cell)} for mapping ${dump(mapping)}`);
      return;
    case sqlLength < datum.length:
      console.error(`datum '${datum}' length ${datum.length} won't fit in sql ${dump(mapping)}`);
      return;
    default:
  }
};

export default class LoadXlsxData {
  fs = fs;
  xlsx = xlsx;
  public bulkData: (string | number | Date)[][] = [];
  public lotNumbers: string[] = [];
  headers: string[] = [];

  constructor(protected ns = null as (NotificationsServer | null)) {}

  async scanForLotNumbers(xlsxPath: string) {
    console.log(`called with ${xlsxPath}`);
    this.bulkData = [];
    const newLotNumbers = [];
    const sheet = await this.readFirstSheet(xlsxPath);
    let emptyRowCounter = 0;
    let row = 1;

    while (emptyRowCounter < 8) {
      const lotNumber = this.findLotNumber(row, sheet);
      if (_.isString(lotNumber)) {
        newLotNumbers.push(lotNumber);
        emptyRowCounter = 0;
      } else {
        emptyRowCounter += 1;
      }
      row++;
    }
    console.log(`scanForLotNumbers found original ${newLotNumbers.length} records versus ${_.uniq(newLotNumbers).length} unique records`);
    this.lotNumbers = newLotNumbers;
  }

  private findLotNumber(row, sheet) {
    const cellAddress = `A${row}`;
    const cell = sheet[cellAddress];
    if (cell) {
      switch (cell.t) {
        case 'n':
          return _.toString(cell.w);
        case 's':
          if (!_.isEmpty(cell.w)) {
            return cell.w;
          }
          break;
        default:
      }
    }
    return null;
  }

  async readWithMap(xlsxPath: string, mapping: InputToSqlMapping[]) {
    const firstSheet = await this.readFirstSheet(xlsxPath);
    let emptyRow = false;
    this.loadHeaders(firstSheet);
    let row = 2; // row 1 is the headers
    while (!emptyRow) {
      const dataRow: (Date | string | number)[] = [];
      emptyRow = true;
      mapping.forEach(c => {
        const cellAddress = `${c.xlsxAddress}${row}`;
        let datum: (Date | string | number) = null;
        if (firstSheet[cellAddress] !== undefined) {
          const cellValue = firstSheet[cellAddress].w || firstSheet[cellAddress].v;
          emptyRow = false;
          switch (c.dataType) {
            case 'date':
              datum = new Date(cellValue);
              break;
            case 'number':
              datum = parseInt(cellValue);
              break;
            case 'string':
              datum = cellValue;
              checkLength(datum, c, firstSheet[cellAddress]);
              break;
            default:
              datum = cellValue;
          }
        }
        dataRow.push(datum);
      });
      if (!emptyRow) {
        this.bulkData.push(dataRow);
        row++;
      }
    }
  }

  private loadHeaders(firstSheet) {
    let col = 0;
    let header;
    do {
      header = null;
      const cellAddress = xlsx.utils.encode_cell({ r: 0, c: col });
      if (_.isObject(firstSheet[cellAddress])) {
        header = firstSheet[cellAddress].w;
        this.headers.push(header);
      }
      col += 1;
    } while (header);
  }

  private async readFirstSheet(xlsxPath: string) {
    if (this.ns) {
      this.ns.notify('INFO', `reading IOL Report`, `reading from ${xlsxPath}`, ['iolUpload']);
    }
    console.info(`reading from ${xlsxPath}`);

    const fs = this.fs;
    const XLSX = this.xlsx;

    const logMemoryUsage = () => {
      const memoryUsage = process.memoryUsage();
      console.info('Memory Usage:', {
        rss: `${(memoryUsage.rss / 1024 / 1024).toFixed(2)} MB`,
        heapTotal: `${(memoryUsage.heapTotal / 1024 / 1024).toFixed(2)} MB`,
        heapUsed: `${(memoryUsage.heapUsed / 1024 / 1024).toFixed(2)} MB`,
        external: `${(memoryUsage.external / 1024 / 1024).toFixed(2)} MB`,
      });
    };

    return new Promise((resolve, reject) => {
      const highWaterMarkSize = 1024 * 1024 * 20; // 200 MB for highWaterMark
      let fileBuffer = Buffer.alloc(0); // Accumulate the data into this buffer
      let totalSize = 0;

      const stream = fs.createReadStream(xlsxPath, { highWaterMark: highWaterMarkSize });

      console.info(`Starting to read file stream from: ${xlsxPath}`);

      logMemoryUsage();

      // Create a set to track unique records (based on unique identifier or hash)
      const seenRecords = new Set();

      stream.on('data', async (chunk: Buffer) => {
        totalSize += chunk.length;
        console.info(`Read ${chunk.length} bytes, total read so far: ${totalSize} bytes`);

        // Accumulate chunks into the fileBuffer
        fileBuffer = Buffer.concat([fileBuffer, chunk]);

        logMemoryUsage();
      });

      // When the file has been completely read, process the accumulated buffer
      stream.on('end', async () => {
        console.info(`File stream reading complete. Total size: ${totalSize} bytes`);
        logMemoryUsage();

        try {
          const sheetData = await processChunk(fileBuffer, XLSX);

          if (sheetData) {
            console.debug(`Processed chunk, current fileBuffer size: ${fileBuffer.length}`);

            let adds = 0;
            let exists = 0;

            // Process each row and check if it's already in the seen set (i.e., already processed)
            for (const row of sheetData) {
              const rowId = row.id; // Assuming 'id' is the unique identifier for each row
              if (seenRecords.has(rowId)) {
                exists++;
              } else {
                seenRecords.add(rowId);
                adds++;
              }
            }

            console.info(`Adds: ${adds}, Exists: ${exists}`);

            // Return the sheet data if needed or just resolve
            resolve(sheetData);
          }
        } catch (err) {
          reject(new Error(`Error processing chunk: ${err.message}`));
        }
      });

      stream.on('error', (err: Error) => {
        console.error(`Error reading file stream: ${err.message}`);
        reject(new Error(`"${xlsxPath}" could not be read because ${err.message}`));
      });

      stream.on('close', () => {
        console.info(`File stream closed for: ${xlsxPath}`);
      });
    });
  }
}
  // Function to process the accumulated buffer (file content)
  async function processChunk(fileBuffer: Buffer, XLSX) {
    try {
      // Parse the accumulated buffer as an XLSX file
      const sheets = XLSX.read(fileBuffer, { type: 'buffer' });
      const sheetNames = sheets.SheetNames;
      if (sheetNames.length > 0) {
        // Assuming we're interested in the first sheet
        return XLSX.utils.sheet_to_json(sheets.Sheets[sheetNames[0]]);
      }
    } catch (err) {
      console.error(`Error processing chunk: ${err.message}`);
      throw new Error(`Error parsing XLSX chunk: ${err.message}`);
    }
  }

  // Example of how to process data without counting duplicates
  function checkForDuplicateData(sheetData: any[], seenRecords: Set<any>) {
    let adds = 0;
    let exists = 0;

    // Loop through each row in the sheet
    for (const row of sheetData) {
      const rowId = row.id; // Assuming 'id' is the unique identifier for each row
      if (seenRecords.has(rowId)) {
        exists++;
      } else {
        seenRecords.add(rowId);
        adds++;
      }
    }

    return { adds, exists };
  }
